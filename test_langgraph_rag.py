#!/usr/bin/env python3
"""
ê°œì„ ëœ LangGraph RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
from rag_utils import answer_with_langgraph_rag, answer_with_rag
from config import GEMINI_API_KEY

def test_improved_langgraph_rag():
    """ê°œì„ ëœ LangGraph RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    # API í‚¤ í™•ì¸
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print("=== ê°œì„ ëœ LangGraph RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ (ë‹¤ì–‘í•œ ìœ í˜•)
    test_queries = [
        # ì“°ë ˆê¸° ì²˜ë¦¬ ê´€ë ¨ ì§ˆë¬¸
        "í•´ìš´ëŒ€êµ¬ì—ì„œ ëŒ€í˜•íê¸°ë¬¼ì„ ì–´ë–»ê²Œ ë²„ë ¤ì•¼ í•˜ë‚˜ìš”?",
        "ë¶€ì‚°ì§„êµ¬ ì“°ë ˆê¸° ë°°ì¶œ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
        
        # ê¶Œë¦¬êµ¬ì œ ê´€ë ¨ ì§ˆë¬¸
        "ì™¸êµ­ì¸ ê·¼ë¡œìì˜ ì„ê¸ˆ ì²´ë¶ˆ ë¬¸ì œëŠ” ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
        "ê·¼ë¡œê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€?",
        
        # ë§›ì§‘ ê´€ë ¨ ì§ˆë¬¸
        "ë¶€ì‚°ì—ì„œ ë§›ìˆëŠ” í•´ì‚°ë¬¼ ë§›ì§‘ ì¶”ì²œí•´ì£¼ì„¸ìš”",
        "ì„œë©´ ê·¼ì²˜ ë§›ì§‘ ì•Œë ¤ì£¼ì„¸ìš”",
        
        # ì¼ë°˜ ì§ˆë¬¸
        "í•œêµ­ì˜ ì˜ë£Œë³´í—˜ ê°€ì… ë°©ë²•ì€?",
        "ë‹¤ë¬¸í™”ê°€ì¡±ì„ ìœ„í•œ êµìœ¡ ì§€ì›ì€ ì–´ë–»ê²Œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
    ]
    
    # ë²¡í„°DB ë¡œë“œ
    try:
        import pickle
        vector_db_path = "ë‹¤ë¬¸í™”.pkl"
        
        if os.path.exists(vector_db_path):
            with open(vector_db_path, 'rb') as f:
                vector_db = pickle.load(f)
            print(f"âœ… ë²¡í„°DB ë¡œë“œ ì™„ë£Œ: {len(vector_db.documents)}ê°œ ë¬¸ì„œ")
        else:
            print(f"âŒ ë²¡í„°DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {vector_db_path}")
            return
            
    except Exception as e:
        print(f"âŒ ë²¡í„°DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ê° ì§ˆë¬¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*50}")
        print(f"--- í…ŒìŠ¤íŠ¸ {i}: {query} ---")
        print(f"{'='*50}")
        
        try:
            # LangGraph RAG í…ŒìŠ¤íŠ¸
            print("ğŸ”„ ê°œì„ ëœ LangGraph RAG ë‹µë³€ ìƒì„± ì¤‘...")
            langgraph_answer = answer_with_langgraph_rag(query, vector_db, GEMINI_API_KEY, "ko")
            print(f"âœ… LangGraph RAG ë‹µë³€:\n{langgraph_answer}")
            
            # ê¸°ë³¸ RAGì™€ ë¹„êµ
            print("\nğŸ”„ ê¸°ë³¸ RAG ë‹µë³€ ìƒì„± ì¤‘...")
            basic_answer = answer_with_rag(query, vector_db, GEMINI_API_KEY, "ko")
            print(f"âœ… ê¸°ë³¸ RAG ë‹µë³€:\n{basic_answer}")
            
            # ë‹µë³€ í’ˆì§ˆ ë¹„êµ
            print(f"\nğŸ“Š ë‹µë³€ í’ˆì§ˆ ë¹„êµ:")
            print(f"LangGraph RAG: {len(langgraph_answer)}ì")
            print(f"ê¸°ë³¸ RAG: {len(basic_answer)}ì")
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            langgraph_score = calculate_answer_quality(langgraph_answer, query)
            basic_score = calculate_answer_quality(basic_answer, query)
            
            print(f"LangGraph RAG í’ˆì§ˆ ì ìˆ˜: {langgraph_score:.2f}")
            print(f"ê¸°ë³¸ RAG í’ˆì§ˆ ì ìˆ˜: {basic_score:.2f}")
            
            if langgraph_score > basic_score:
                print("ğŸ‰ LangGraph RAGê°€ ë” ì¢‹ì€ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!")
            elif basic_score > langgraph_score:
                print("âš ï¸ ê¸°ë³¸ RAGê°€ ë” ì¢‹ì€ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            else:
                print("ğŸ¤ ë‘ ì‹œìŠ¤í…œì˜ ë‹µë³€ í’ˆì§ˆì´ ë¹„ìŠ·í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i} ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

def calculate_answer_quality(answer: str, query: str) -> float:
    """ë‹µë³€ í’ˆì§ˆì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if not answer or len(answer) < 20:
        return 0.0
    
    # í’ˆì§ˆ ì§€í‘œë“¤
    quality_score = 0.0
    
    # ê¸¸ì´ ì ìˆ˜ (ì ì ˆí•œ ê¸¸ì´)
    length_score = min(len(answer) / 300, 1.0)  # 300ì ê¸°ì¤€
    quality_score += length_score * 0.2
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
    query_keywords = set(query.lower().split())
    answer_keywords = set(answer.lower().split())
    keyword_overlap = len(query_keywords.intersection(answer_keywords)) / max(len(query_keywords), 1)
    quality_score += keyword_overlap * 0.4
    
    # êµ¬ì²´ì„± ì ìˆ˜ (ìˆ«ì, êµ¬ì²´ì  ì •ë³´ í¬í•¨)
    specificity_score = 0.0
    if any(char.isdigit() for char in answer):
        specificity_score += 0.2
    if any(word in answer.lower() for word in ["ì „í™”", "ì—°ë½ì²˜", "ì£¼ì†Œ", "ì‹œê°„", "ê¸ˆì•¡", "ë¹„ìš©"]):
        specificity_score += 0.2
    if any(word in answer.lower() for word in ["ë°©ë²•", "ì ˆì°¨", "ë‹¨ê³„", "ìˆœì„œ"]):
        specificity_score += 0.2
    quality_score += specificity_score
    
    # ëª…í™•ì„± ì ìˆ˜ (ë¶ˆëª…í™•í•œ í‘œí˜„ì´ ì ì„ìˆ˜ë¡ ë†’ìŒ)
    clarity_score = 1.0
    unclear_phrases = ["ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "í™•ì¸í•´ë³´ì„¸ìš”"]
    for phrase in unclear_phrases:
        if phrase in answer:
            clarity_score -= 0.3
    quality_score += max(clarity_score, 0) * 0.2
    
    return min(quality_score, 1.0)

def test_langgraph_features():
    """LangGraph íŠ¹ë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== LangGraph íŠ¹ë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    # ì¬ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    print("ğŸ”„ ì¬ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
    test_query = "ë¶€ì‚°ì—ì„œ íŠ¹ë³„íˆ ë§›ìˆëŠ” ìŒì‹ì ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    
    try:
        # ë²¡í„°DB ë¡œë“œ
        import pickle
        vector_db_path = "ë‹¤ë¬¸í™”.pkl"
        
        if os.path.exists(vector_db_path):
            with open(vector_db_path, 'rb') as f:
                vector_db = pickle.load(f)
            
            # LangGraph RAG í…ŒìŠ¤íŠ¸
            answer = answer_with_langgraph_rag(test_query, vector_db, GEMINI_API_KEY, "ko")
            print(f"âœ… ì¬ê²€ìƒ‰ í¬í•¨ ë‹µë³€:\n{answer}")
            
        else:
            print("âŒ ë²¡í„°DB íŒŒì¼ì´ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì¬ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def test_langgraph_availability():
    """LangGraph ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸"""
    print("=== LangGraph ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        from langgraph.graph import StateGraph, END
        from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
        from langchain_core.prompts import ChatPromptTemplate
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_community.vectorstores import FAISS
        from langchain_core.runnables import RunnablePassthrough
        from langchain_core.output_parsers import StrOutputParser
        
        print("âœ… LangGraph ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥")
        return True
        
    except ImportError as e:
        print(f"âŒ LangGraph ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install langgraph langchain-google-genai langchain-community")
        return False

if __name__ == "__main__":
    # LangGraph ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if test_langgraph_availability():
        # ê°œì„ ëœ LangGraph RAG í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_improved_langgraph_rag()
        
        # íŠ¹ë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        test_langgraph_features()
    else:
        print("LangGraphë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.") 