import pickle
import os
from rag_utils import SimpleVectorDB

def check_pkl_content(file_path):
    """PKL íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    print(f"=== {file_path} íŒŒì¼ ë¶„ì„ ===")
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        return
    
    print(f"íŒŒì¼ í¬ê¸°: {os.path.getsize(file_path)} bytes")
    
    try:
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        
        print(f"âœ… íŒŒì¼ ë¡œë“œ ì„±ê³µ!")
        print(f"ë°ì´í„° íƒ€ì…: {type(data)}")
        
        # SimpleVectorDB ê°ì²´ì¸ì§€ í™•ì¸
        if hasattr(data, 'documents'):
            print(f"ğŸ“š ë¬¸ì„œ ìˆ˜: {len(data.documents)}")
            print(f"ğŸ“Š ì„ë² ë”© ìˆ˜: {len(data.doc_embeddings) if hasattr(data, 'doc_embeddings') else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
            
            # ì²˜ìŒ 3ê°œ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
            print("\n=== ì²˜ìŒ 3ê°œ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° ===")
            for i, doc in enumerate(data.documents[:3]):
                print(f"\n--- ë¬¸ì„œ {i+1} ---")
                print(f"ë‚´ìš© ê¸¸ì´: {len(doc['page_content'])} ë¬¸ì")
                print(f"ë©”íƒ€ë°ì´í„°: {doc.get('metadata', 'ì—†ìŒ')}")
                print(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc['page_content'][:200]}...")
        
        # ChromaDB í˜•ì‹ì¸ì§€ í™•ì¸
        elif hasattr(data, 'docstore') and hasattr(data.docstore, '_dict'):
            print(f"ğŸ“š ChromaDB í˜•ì‹ - ë¬¸ì„œ ìˆ˜: {len(data.docstore._dict)}")
            
            # ì²˜ìŒ 3ê°œ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
            print("\n=== ì²˜ìŒ 3ê°œ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° ===")
            for i, (doc_id, doc) in enumerate(list(data.docstore._dict.items())[:3]):
                print(f"\n--- ë¬¸ì„œ {i+1} (ID: {doc_id}) ---")
                if hasattr(doc, 'page_content'):
                    print(f"ë‚´ìš© ê¸¸ì´: {len(doc.page_content)} ë¬¸ì")
                    print(f"ë©”íƒ€ë°ì´í„°: {getattr(doc, 'metadata', 'ì—†ìŒ')}")
                    print(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:200]}...")
        
        # ê¸°íƒ€ í˜•ì‹
        else:
            print(f"ğŸ“‹ ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ì˜ ë°ì´í„°")
            print(f"ì†ì„±ë“¤: {dir(data)}")
            
            # ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            if isinstance(data, list):
                print(f"ë¦¬ìŠ¤íŠ¸ ê¸¸ì´: {len(data)}")
                if len(data) > 0:
                    print(f"ì²« ë²ˆì§¸ í•­ëª© íƒ€ì…: {type(data[0])}")
                    print(f"ì²« ë²ˆì§¸ í•­ëª© ë¯¸ë¦¬ë³´ê¸°: {str(data[0])[:200]}...")
            
            # ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
            elif isinstance(data, dict):
                print(f"ë”•ì…”ë„ˆë¦¬ í‚¤ë“¤: {list(data.keys())}")
                for key, value in list(data.items())[:3]:
                    print(f"í‚¤ '{key}': {type(value)} - {str(value)[:100]}...")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ëª¨ë“  ë²¡í„°DB íŒŒì¼ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    pkl_files = [
        "vector_db_merged.pkl",
        "vector_db_multi.pkl", 
        "vector_db_multi2.pkl",
        "vector_db_64multi.pkl"
    ]
    
    for file_path in pkl_files:
        if os.path.exists(file_path):
            check_pkl_content(file_path)
            print("\n" + "="*50 + "\n")
        else:
            print(f"âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")

if __name__ == "__main__":
    main() 